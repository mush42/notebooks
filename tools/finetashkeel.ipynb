{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTashkeel\n",
    "This notebook allows you to upload a text file containing undiacritized text Arabic lines, and diacritize them using [FineTashkeel](https://huggingface.co/mush42/fine-tashkeel/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install/upgrade packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install transformers tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plumming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import enum\n",
    "import re\n",
    "\n",
    "\n",
    "MODEL_ID = \"mush42/fine-tashkeel\"\n",
    "OUTPUT_FILENAME = \"diac.txt\"\n",
    "WHITESPACE_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "\n",
    "class ArabicDiacritics(enum.Enum):\n",
    "    \"\"\"All possible Arabic diacritics.\"\"\"\n",
    "\n",
    "    NO_DIACRITIC = \"\"\n",
    "    SUKOON = \"ْ\"\n",
    "    SHADDA = \"ّ\"\n",
    "    DAMMA = \"ُ\"\n",
    "    FATHA = \"َ\"\n",
    "    KASRA = \"ِ\"\n",
    "    TANWEEN_DAMMA = \"ٌ\"\n",
    "    TANWEEN_FATHA = \"ً\"\n",
    "    TANWEEN_KASRA = \"ٍ\"\n",
    "    SHADDA_PLUS_DAMMA = \"ُّ\"\n",
    "    SHADDA_PLUS_FATHA = \"َّ\"\n",
    "    SHADDA_PLUS_KASRA = \"ِّ\"\n",
    "    SHADDA_PLUS_TANWEEN_DAMMA = \"ٌّ\"\n",
    "    SHADDA_PLUS_TANWEEN_FATHA = \"ًّ\"\n",
    "    SHADDA_PLUS_TANWEEN_KASRA = \"ٍّ\"\n",
    "\n",
    "    @classmethod\n",
    "    def chars(cls):\n",
    "        return {\n",
    "            cls.SUKOON,\n",
    "            cls.SHADDA,\n",
    "            cls.DAMMA,\n",
    "            cls.FATHA,\n",
    "            cls.KASRA,\n",
    "            cls.TANWEEN_DAMMA,\n",
    "            cls.TANWEEN_FATHA,\n",
    "            cls.TANWEEN_KASRA,\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def valid(cls):\n",
    "        return {\n",
    "            cls.NO_DIACRITIC,\n",
    "            cls.SUKOON,\n",
    "            cls.DAMMA,\n",
    "            cls.FATHA,\n",
    "            cls.KASRA,\n",
    "            cls.TANWEEN_DAMMA,\n",
    "            cls.TANWEEN_FATHA,\n",
    "            cls.TANWEEN_KASRA,\n",
    "            cls.SHADDA_PLUS_DAMMA,\n",
    "            cls.SHADDA_PLUS_FATHA,\n",
    "            cls.SHADDA_PLUS_KASRA,\n",
    "            cls.SHADDA_PLUS_TANWEEN_DAMMA,\n",
    "            cls.SHADDA_PLUS_TANWEEN_FATHA,\n",
    "            cls.SHADDA_PLUS_TANWEEN_KASRA,\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def diacritic_to_label(cls):\n",
    "        return {\n",
    "            member.value: name\n",
    "            for (name, member) in cls.__members__.items()\n",
    "        }\n",
    "\n",
    "\n",
    "WORD_SEPARATOR = chr(0x20)\n",
    "ARABIC_LETTERS = frozenset(\n",
    "    {chr(x) for x in (list(range(0x0621, 0x63B)) + list(range(0x0641, 0x064B)))}\n",
    ")\n",
    "PUNCTUATIONS = frozenset({\".\", \"،\", \":\", \"؛\", \"-\", \"؟\", \"!\", \"(\", \")\", \"[\", \"]\", '\"', \"«\", \"»\", \"/\",})\n",
    "DIACRITIC_CHARS = {diac.value for diac in ArabicDiacritics.chars()}\n",
    "ALL_VALID_DIACRITICS = {m.value for m in ArabicDiacritics.valid()}\n",
    "DIACRITIC_LABELS = ArabicDiacritics.diacritic_to_label()\n",
    "ARABIC_VOWELS = {\n",
    "    chr(c)\n",
    "    for c in [0x621, 0x622, 0x623, 0x624, 0x625, 0x626, 0x627, 0x648, 0x649, 0x64a]\n",
    "}\n",
    "SENTENCE_DELIMITERS = {\".\", \"؟\", \"!\", \"،\", \":\", \"؛\", \"(\", \")\", \"[\", \"]\", '\"', \"«\", \"»\",}\n",
    "WORD_DELIMITERS = {WORD_SEPARATOR, *SENTENCE_DELIMITERS}\n",
    "\n",
    "_ARABIC_NUMERALS = [str(i) for i in range(10)]\n",
    "_INDIAN_NUMERALS = [chr(c) for c in range(0x660, 0x66a)]\n",
    "NUMERAL_CHARS = _ARABIC_NUMERALS + _INDIAN_NUMERALS\n",
    "VALID_ARABIC_CHARS = {\n",
    "    WORD_SEPARATOR,\n",
    "    *ARABIC_LETTERS,\n",
    "    *PUNCTUATIONS,\n",
    "    *DIACRITIC_CHARS,\n",
    "    *NUMERAL_CHARS\n",
    "}\n",
    "\n",
    "\n",
    "def collapse_whitespace(text):\n",
    "    text = re.sub(WHITESPACE_RE, \" \", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def basic_cleaner(text):\n",
    "    text = collapse_whitespace(text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def valid_arabic_cleaner(text):\n",
    "    return valid_vocab_char_cleaner(text, VALID_ARABIC_CHARS)\n",
    "\n",
    "\n",
    "def valid_vocab_char_cleaner(text, vocab_chars):\n",
    "    text = filter(lambda c: c in vocab_chars, text)\n",
    "    text = collapse_whitespace(\"\".join(list(text)))\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def diacritics_cleaner(text: str) -> str:\n",
    "    return text.translate(str.maketrans(\"\", \"\", \"\".join(DIACRITIC_CHARS)))\n",
    "\n",
    "def fix_puncs(text):\n",
    "    puncs = [\".\", \"؛\", \"،\", \"؟\", \"!\", \",\", \";\", \"?\"]\n",
    "    for p in puncs:\n",
    "        text = text.replace(\" \" + p, p)\n",
    "        text = text.replace(\"  \" + p, p)\n",
    "        text = text.replace(\"   \" + p, p)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload \"lines.txt\" Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "source_text = uploaded[\"lines.txt\"].decode(\"utf-8\")\n",
    "source_lines = source_text.splitlines()\n",
    "source_lines = [line for l in source_lines if (line := l.strip())]\n",
    "print(f\"Found {len(source_lines)} lines in the uploaded file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start diacritization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, ByT5Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "CLEAN_ARABIC_CHARS = frozenset(VALID_ARABIC_CHARS - set(DIACRITIC_CHARS))\n",
    "\n",
    "tok = ByT5Tokenizer(extra_ids=0)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_ID)\n",
    "\n",
    "\n",
    "def diac(sent):\n",
    "    input_sent = valid_vocab_char_cleaner(\n",
    "        fix_puncs(sent),\n",
    "        CLEAN_ARABIC_CHARS\n",
    "    )\n",
    "    inputs = tok(input_sent, return_tensors='pt')\n",
    "    max_new_tokens = len(sent) * 5\n",
    "    out = model.generate(inputs.input_ids, max_new_tokens=max_new_tokens) \n",
    "    return tok.batch_decode(out, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "with open(OUTPUT_FILENAME, \"a\", encoding=\"utf-8\") as outfile:\n",
    "    for line in tqdm(source_lines, total=len(source_lines), desc=\"diacritizing line\"):\n",
    "        sents = \"\\n\".join(diac(line))\n",
    "        outfile.write(sents)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Process done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download diacritized file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download(OUTPUT_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
